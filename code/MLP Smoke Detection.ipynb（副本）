{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLP Smoke Detection.ipynb","provenance":[],"mount_file_id":"1NtQ7U30CEH06MmBUBiAtSAHPs2JyQ2RA","authorship_tag":"ABX9TyMk54BSjjkbWKS0xf6/aHjy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d9f5617f48094b1daf1d7c0b3da6beaf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfd59182ebbb4a7598db9d6cf235e5dc","IPY_MODEL_0bd24cad6c80428eaed12446831a2278","IPY_MODEL_1dd9927529014a128df419c042a27731"],"layout":"IPY_MODEL_3cf55a4445934545a22cc97875774452"}},"dfd59182ebbb4a7598db9d6cf235e5dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5738cecb9b464bcba945e81fa8f61356","placeholder":"​","style":"IPY_MODEL_84c8d434df82469095255b5ac41aacb3","value":"100%"}},"0bd24cad6c80428eaed12446831a2278":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_820c5e2d9e0f44b48ddbd31175f555dd","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8268315a214491ba837ddc14fb05754","value":2}},"1dd9927529014a128df419c042a27731":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3df0cd26219a4c2e88856f6aa571d28b","placeholder":"​","style":"IPY_MODEL_7c571f3636b047d080cddcd0ff61ed70","value":" 2/2 [00:13&lt;00:00,  6.61s/it]"}},"3cf55a4445934545a22cc97875774452":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5738cecb9b464bcba945e81fa8f61356":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84c8d434df82469095255b5ac41aacb3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"820c5e2d9e0f44b48ddbd31175f555dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8268315a214491ba837ddc14fb05754":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3df0cd26219a4c2e88856f6aa571d28b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c571f3636b047d080cddcd0ff61ed70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Tv1akwGtNQO5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648812383680,"user_tz":-480,"elapsed":134660,"user":{"displayName":"莫宇皓","userId":"09578917465057778090"}},"outputId":"8861b1da-f6cb-4658-909a-a8b2a7fbd82c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n","Collecting pip\n","  Downloading pip-22.0.4-py3-none-any.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 27.6 MB/s \n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 21.1.3\n","    Uninstalling pip-21.1.3:\n","      Successfully uninstalled pip-21.1.3\n","Successfully installed pip-22.0.4\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.4.0)\n","Collecting setuptools\n","  Downloading setuptools-61.3.0-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (0.37.1)\n","Installing collected packages: setuptools\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 57.4.0\n","    Uninstalling setuptools-57.4.0:\n","      Successfully uninstalled setuptools-57.4.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed setuptools-61.3.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting mxnet<2.0.0\n","  Downloading mxnet-1.9.0-py3-none-manylinux2014_x86_64.whl (47.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<2.0.0) (1.21.5)\n","Collecting graphviz<0.9.0,>=0.8.1\n","  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet<2.0.0) (2.23.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet<2.0.0) (3.0.4)\n","Installing collected packages: graphviz, mxnet\n","  Attempting uninstall: graphviz\n","    Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.9.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting autogluon==0.2.0\n","  Downloading autogluon-0.2.0-py3-none-any.whl (5.4 kB)\n","Collecting autogluon.tabular[all]==0.2.0\n","  Downloading autogluon.tabular-0.2.0-py3-none-any.whl (250 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.5/250.5 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting autogluon.core==0.2.0\n","  Downloading autogluon.core-0.2.0-py3-none-any.whl (334 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m334.3/334.3 KB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting autogluon.mxnet==0.2.0\n","  Downloading autogluon.mxnet-0.2.0-py3-none-any.whl (28 kB)\n","Collecting autogluon.extra==0.2.0\n","  Downloading autogluon.extra-0.2.0-py3-none-any.whl (24 kB)\n","Collecting autogluon.text==0.2.0\n","  Downloading autogluon.text-0.2.0-py3-none-any.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting autogluon.vision==0.2.0\n","  Downloading autogluon.vision-0.2.0-py3-none-any.whl (31 kB)\n","Collecting autogluon.features==0.2.0\n","  Downloading autogluon.features-0.2.0-py3-none-any.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas<2.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (1.3.5)\n","Requirement already satisfied: tornado>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (5.1.1)\n","Collecting scipy<1.7,>=1.5.4\n","  Downloading scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.4/27.4 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting scikit-learn<0.25,>=0.23.2\n","  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (1.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (3.2.2)\n","Collecting dill==0.3.3\n","  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 KB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (2.23.0)\n","Requirement already satisfied: dask>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (2.12.0)\n","Collecting distributed>=2.6.0\n","  Downloading distributed-2022.2.0-py3-none-any.whl (837 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.0/837.0 KB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting boto3\n","  Downloading boto3-1.21.31-py3-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.3/132.3 KB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ConfigSpace==0.4.18\n","  Downloading ConfigSpace-0.4.18.tar.gz (950 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.6/950.6 KB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (0.8.4)\n","Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (4.63.0)\n","Collecting paramiko>=2.4\n","  Downloading paramiko-2.10.3-py2.py3-none-any.whl (211 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.9/211.9 KB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpy==1.19.5\n","  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.2.0->autogluon==0.2.0) (0.29.28)\n","Collecting gluoncv<0.11,>=0.10.1.post0\n","  Downloading gluoncv-0.10.5-py2.py3-none-any.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting openml\n","  Downloading openml-0.12.2.tar.gz (119 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 KB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from autogluon.extra==0.2.0->autogluon==0.2.0) (3.6.4)\n","Requirement already satisfied: Pillow<=8.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.mxnet==0.2.0->autogluon==0.2.0) (7.1.2)\n","Requirement already satisfied: networkx<3.0,>=2.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (2.6.3)\n","Collecting psutil<5.9,>=5.7.3\n","  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.3/296.3 KB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting catboost<0.26,>=0.24.0\n","  Downloading catboost-0.25.1-cp37-none-manylinux1_x86_64.whl (67.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (1.10.0+cu111)\n","Collecting lightgbm<4.0,>=3.0\n","  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xgboost<1.4,>=1.3.2\n","  Downloading xgboost-1.3.3-py3-none-manylinux2010_x86_64.whl (157.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.5/157.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastai<3.0,>=2.0\n","  Downloading fastai-2.5.5-py3-none-any.whl (187 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.5/187.5 KB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting autogluon-contrib-nlp==0.0.1b20210201\n","  Downloading autogluon_contrib_nlp-0.0.1b20210201-py3-none-any.whl (157 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 KB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.7/dist-packages (from autogluon.text==0.2.0->autogluon==0.2.0) (6.0.1)\n","Collecting d8<1.0,>=0.0.2\n","  Downloading d8-0.0.2.post0-py3-none-any.whl (28 kB)\n","Collecting tokenizers==0.9.4\n","  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon==0.2.0) (3.17.3)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon==0.2.0) (2019.12.20)\n","Collecting sentencepiece==0.1.95\n","  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yacs>=0.1.6\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sacremoses>=0.0.38\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m895.2/895.2 KB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting contextvars\n","  Downloading contextvars-2.4.tar.gz (9.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting flake8\n","  Downloading flake8-4.0.1-py2.py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace==0.4.18->autogluon.core==0.2.0->autogluon==0.2.0) (3.0.7)\n","Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->autogluon.core==0.2.0->autogluon==0.2.0) (0.16.0)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (5.5.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (1.15.0)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from d8<1.0,>=0.0.2->autogluon.vision==0.2.0->autogluon==0.2.0) (1.5.12)\n","Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (2.4.0)\n","Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (7.1.2)\n","Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (1.7.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (3.13)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (2.11.3)\n","Collecting cloudpickle>=1.5.0\n","  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (21.3)\n","Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (0.11.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (61.3.0)\n","Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (2.1.0)\n","Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (1.0.3)\n","Collecting dask>=2.6.0\n","  Downloading dask-2022.2.0-py3-none-any.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting partd>=0.3.10\n","  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n","Collecting pyyaml\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m596.3/596.3 KB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fsspec>=0.6.0\n","  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.1/136.1 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<4 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (2.2.4)\n","Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (1.0.2)\n","Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (22.0.4)\n","Collecting fastcore<1.5,>=1.3.27\n","  Downloading fastcore-1.4.1-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 KB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastdownload<2,>=0.0.5\n","  Downloading fastdownload-0.0.5-py3-none-any.whl (13 kB)\n","Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (0.11.1+cu111)\n","Collecting portalocker\n","  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n","Collecting autocfg\n","  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv<0.11,>=0.10.1.post0->autogluon.extra==0.2.0->autogluon==0.2.0) (4.1.2.30)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm<4.0,>=3.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (0.37.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.2.0->autogluon==0.2.0) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<2.0,>=1.0.0->autogluon.core==0.2.0->autogluon==0.2.0) (2018.9)\n","Collecting cryptography>=2.5\n","  Downloading cryptography-36.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pynacl>=1.0.1\n","  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 KB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting bcrypt>=3.1.3\n","  Downloading bcrypt-3.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25,>=0.23.2->autogluon.core==0.2.0->autogluon==0.2.0) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.25,>=0.23.2->autogluon.core==0.2.0->autogluon==0.2.0) (3.1.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (3.10.0.2)\n","Collecting s3transfer<0.6.0,>=0.5.0\n","  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting botocore<1.25.0,>=1.24.31\n","  Downloading botocore-1.24.31-py3-none-any.whl (8.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n","  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.2.0->autogluon==0.2.0) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->autogluon.core==0.2.0->autogluon==0.2.0) (1.4.0)\n","Collecting liac-arff>=2.4.0\n","  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting xmltodict\n","  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n","Collecting minio\n","  Downloading minio-7.1.5-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 KB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.2.0->autogluon==0.2.0) (21.4.0)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.2.0->autogluon==0.2.0) (1.11.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.2.0->autogluon==0.2.0) (1.4.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.2.0->autogluon==0.2.0) (8.12.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->autogluon.extra==0.2.0->autogluon==0.2.0) (0.7.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.2.0->autogluon==0.2.0) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.2.0->autogluon==0.2.0) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.2.0->autogluon==0.2.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autogluon.core==0.2.0->autogluon==0.2.0) (1.24.3)\n","Requirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.2.0->autogluon==0.2.0) (1.15.0)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting locket\n","  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (1.0.6)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (1.1.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (3.0.6)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (0.4.1)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (7.4.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (2.0.6)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (1.0.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (0.9.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4->fastai<3.0,>=2.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (1.0.5)\n","Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (1.0.1)\n","Collecting immutables>=0.9\n","  Downloading immutables-0.17-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.5/116.5 KB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting importlib-metadata<4.3\n","  Downloading importlib_metadata-4.2.0-py3-none-any.whl (16 kB)\n","Collecting mccabe<0.7.0,>=0.6.0\n","  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n","Collecting pycodestyle<2.9.0,>=2.8.0\n","  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyflakes<2.5.0,>=2.4.0\n","  Downloading pyflakes-2.4.0-py2.py3-none-any.whl (69 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 KB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->distributed>=2.6.0->autogluon.core==0.2.0->autogluon==0.2.0) (2.0.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.2.0->autogluon==0.2.0) (6.1.1)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost<0.26,>=0.24.0->autogluon.tabular[all]==0.2.0->autogluon==0.2.0) (8.0.1)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon==0.2.0) (0.8.9)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4->autogluon.core==0.2.0->autogluon==0.2.0) (2.21)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.3->flake8->autogluon-contrib-nlp==0.0.1b20210201->autogluon.text==0.2.0->autogluon==0.2.0) (3.7.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->d8<1.0,>=0.0.2->autogluon.vision==0.2.0->autogluon==0.2.0) (1.3)\n","Building wheels for collected packages: ConfigSpace, openml, liac-arff, contextvars\n","  Building wheel for ConfigSpace (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.18-cp37-cp37m-linux_x86_64.whl size=2881992 sha256=94e1ded09c5b3d2d0ef9c33cebe21bd85ae14187b0783e609fa966344f2c4239\n","  Stored in directory: /root/.cache/pip/wheels/36/f7/0f/36f368c419ea1a8024fc3d6c078c3111dfef43fa1d14cfebe0\n","  Building wheel for openml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openml: filename=openml-0.12.2-py3-none-any.whl size=137325 sha256=1e54a7bea411e4575c7e513db6af6930dc8349f3d3007e8202abc046f2e7ceb7\n","  Stored in directory: /root/.cache/pip/wheels/6a/20/88/cf4ac86aa18e2cd647ed16ebe274a5dacee9d0075fa02af250\n","  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11733 sha256=c29438f2fc142d0f2ac3fa4e1cb9d8f73ae46c1e72b75a9c4bb9c48b117fa97e\n","  Stored in directory: /root/.cache/pip/wheels/1f/0f/15/332ca86cbebf25ddf98518caaf887945fbe1712b97a0f2493b\n","  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7681 sha256=973feab27306089bf735c81afb0f772864f6458e404a7168cc933727ffb42d7d\n","  Stored in directory: /root/.cache/pip/wheels/0a/11/79/e70e668095c0bb1f94718af672ef2d35ee7a023fee56ef54d9\n","Successfully built ConfigSpace openml liac-arff contextvars\n","Installing collected packages: tokenizers, sentencepiece, mccabe, xxhash, xmltodict, urllib3, sacremoses, pyyaml, pyflakes, pycodestyle, psutil, portalocker, numpy, locket, liac-arff, jmespath, importlib-metadata, immutables, fsspec, dill, colorama, cloudpickle, yacs, scipy, sacrebleu, pynacl, partd, minio, flake8, fastcore, cryptography, contextvars, ConfigSpace, botocore, bcrypt, autocfg, xgboost, scikit-learn, s3transfer, paramiko, gluoncv, fastdownload, dask, catboost, autogluon-contrib-nlp, openml, lightgbm, distributed, d8, boto3, fastai, autogluon.core, autogluon.mxnet, autogluon.features, autogluon.extra, autogluon.vision, autogluon.text, autogluon.tabular, autogluon\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: psutil\n","    Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.5\n","    Uninstalling numpy-1.21.5:\n","      Successfully uninstalled numpy-1.21.5\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib-metadata 4.11.3\n","    Uninstalling importlib-metadata-4.11.3:\n","      Successfully uninstalled importlib-metadata-4.11.3\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.3.0\n","    Uninstalling cloudpickle-1.3.0:\n","      Successfully uninstalled cloudpickle-1.3.0\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","  Attempting uninstall: xgboost\n","    Found existing installation: xgboost 0.90\n","    Uninstalling xgboost-0.90:\n","      Successfully uninstalled xgboost-0.90\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.0.2\n","    Uninstalling scikit-learn-1.0.2:\n","      Successfully uninstalled scikit-learn-1.0.2\n","  Attempting uninstall: dask\n","    Found existing installation: dask 2.12.0\n","    Uninstalling dask-2.12.0:\n","      Successfully uninstalled dask-2.12.0\n","  Attempting uninstall: lightgbm\n","    Found existing installation: lightgbm 2.2.3\n","    Uninstalling lightgbm-2.2.3:\n","      Successfully uninstalled lightgbm-2.2.3\n","  Attempting uninstall: distributed\n","    Found existing installation: distributed 1.25.3\n","    Uninstalling distributed-1.25.3:\n","      Successfully uninstalled distributed-1.25.3\n","  Attempting uninstall: fastai\n","    Found existing installation: fastai 1.0.61\n","    Uninstalling fastai-1.0.61:\n","      Successfully uninstalled fastai-1.0.61\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n","yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\n","tensorflow 2.8.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.3 which is incompatible.\n","markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 4.2.0 which is incompatible.\n","gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed ConfigSpace-0.4.18 autocfg-0.0.8 autogluon-0.2.0 autogluon-contrib-nlp-0.0.1b20210201 autogluon.core-0.2.0 autogluon.extra-0.2.0 autogluon.features-0.2.0 autogluon.mxnet-0.2.0 autogluon.tabular-0.2.0 autogluon.text-0.2.0 autogluon.vision-0.2.0 bcrypt-3.2.0 boto3-1.21.31 botocore-1.24.31 catboost-0.25.1 cloudpickle-2.0.0 colorama-0.4.4 contextvars-2.4 cryptography-36.0.2 d8-0.0.2.post0 dask-2022.2.0 dill-0.3.3 distributed-2022.2.0 fastai-2.5.5 fastcore-1.4.1 fastdownload-0.0.5 flake8-4.0.1 fsspec-2022.3.0 gluoncv-0.10.5 immutables-0.17 importlib-metadata-4.2.0 jmespath-1.0.0 liac-arff-2.5.0 lightgbm-3.3.2 locket-0.2.1 mccabe-0.6.1 minio-7.1.5 numpy-1.19.5 openml-0.12.2 paramiko-2.10.3 partd-1.2.0 portalocker-2.4.0 psutil-5.8.0 pycodestyle-2.8.0 pyflakes-2.4.0 pynacl-1.5.0 pyyaml-6.0 s3transfer-0.5.2 sacrebleu-2.0.0 sacremoses-0.0.49 scikit-learn-0.24.2 scipy-1.6.3 sentencepiece-0.1.95 tokenizers-0.9.4 urllib3-1.25.11 xgboost-1.3.3 xmltodict-0.12.0 xxhash-3.0.0 yacs-0.1.8\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip3 install -U pip\n","!pip3 install -U setuptools wheel\n","!pip3 install -U \"mxnet<2.0.0\"\n","!pip3 install autogluon==0.2.0 \n","# 一共会消耗时间3分9秒"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from collections import OrderedDict\n","import autogluon.core as ag\n","print(torch.cuda.is_available())\n","\n","# @ag.obj(\n","#     hidden_vertex=ag.space.Categorical(128,256,512,1024), #\n","#     num_layer=ag.space.Int(2,6,3), #从2到6层都用一次，先试试3\n","#     # BN = ag.Categorical(0,1), #懒得写了直接在这定义了\n","#     # Drop = ag.Categorical(0,1),\n","# )\n","class FCN(nn.Module):\n","    def __init__(self, input_vertex, hidden_vertex,num_layer, BN,Drop):\n","        super().__init__()\n","        self.iv = input_vertex\n","        self.ov = 2\n","        self.hv = hidden_vertex\n","        self.nl = num_layer\n","        input_layer = [\n","                nn.Linear(self.iv, self.hv),\n","                nn.ReLU(),\n","            ]\n","        output_layer = [\n","            #nn.Dropout(0.5),\n","            nn.Linear(self.hv,self.ov),\n","            #nn.Dropout(0.5),\n","             ####################\n","        ]\n","        self.input_layer = nn.Sequential(*input_layer)\n","        self.output_layer = nn.Sequential(*output_layer)\n","        self.hidden_layer = nn.Sequential()\n","        self.hidden_layer = self.add_hidden_layer(BN,Drop)\n","\n","        if BN:\n","            self.input_layer.add_module('BatchNorInput',nn.BatchNorm1d(self.hv))\n","        if Drop:\n","            self.input_layer.add_module('DropoutInput',nn.Dropout(Drop))\n","    def add_hidden_layer(self,BN,Drop):\n","        for i in range(self.nl):\n","            #self.hidden_layer.add_module('Dropout{}'.format(i + 1), nn.Dropout(0.5))  #######20210505\n","            self.hidden_layer.add_module('hidden_layer{}'.format(i+1),nn.Linear(self.hv,self.hv))\n","            #self.hidden_layer.add_module('BatchNor{}'.format(i + 1), nn.BatchNorm1d(self.hv))\n","            #self.hidden_layer.add_module('Dropout{}'.format(i + 1), nn.Dropout(0.5))\n","            self.hidden_layer.add_module('ReLU{}'.format(i+1),nn.ReLU())\n","            if BN:\n","                self.hidden_layer.add_module('BatchNorHid{}'.format(i + 1), nn.BatchNorm1d(self.hv))\n","            if Drop:\n","                self.hidden_layer.add_module('DropoutHid{}'.format(i + 1), nn.Dropout(Drop))\n","        return self.hidden_layer\n","\n","\n","    def forward(self, x):\n","        x = self.input_layer(x)\n","        x = self.hidden_layer(x)\n","        x = self.output_layer(x)\n","        return x\n","\n","if __name__=='__main__':\n","    tensor = torch.rand([2,18])\n","    label = torch.Tensor([1,1]).long()\n","    net = FCN(12,21,2,1,1)\n","    \n","    \n","    opt = torch.optim.SGD(net.parameters(),lr=0.1)\n","  \n"],"metadata":{"id":"L4vEtsPxR1y-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import psutil\n","mem = psutil.virtual_memory()\n","# 系统总计内存(单位字节)\n","zj = float(mem.total) \n","# 系统已经使用内存(单位字节)\n","ysy = float(mem.used)\n","print(zj)\n","print(mem.used)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lkujKnZmcdM6","executionInfo":{"status":"ok","timestamp":1648812471237,"user_tz":-480,"elapsed":507,"user":{"displayName":"莫宇皓","userId":"09578917465057778090"}},"outputId":"402be578-60b6-4f04-9da7-9d70caff17ad"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["13622190080.0\n","1240354816\n"]}]},{"cell_type":"code","source":["# 这里一共耗时一分钟/24秒不等\n","import torch\n","import os\n","import numpy as np\n","import glob\n","from osgeo import gdal\n","import time\n","import torch.utils.data as Data\n","import random\n","import psutil\n","mem = psutil.virtual_memory()\n","\n","def find_pix_index(pix, fn):\n","    #pix包含了一个像元的所有数据，19个波段\n","    date = fn.split('\\\\')[-2]\n","    t = fn.split('\\\\')[-1][:4]\n","    fn = r'E:\\SmokeDetection\\source\\new_new_data\\{}\\{}.tif'.format(date,t)\n","    ary = gdal.Open(fn).ReadAsArray()\n","    for i in range(501):\n","        for j in range(582):\n","            idx = ary[:,i,j] == pix\n","            if idx.sum()==19:\n","                print(pix)\n","                with open(r'E:\\SmokeDetection\\source\\t_place\\wrong_idx.txt','a') as f:\n","                    f.writelines(str(fn)+str([i, j])+'  '+str(pix[-1])+'\\n')\n","                    f.writelines(str(pix)+'\\n')\n","\n","def load_network(net_para, net_file):\n","    # 加载网络，输出的是训练好的网络模型\n","    # net_para是网络参数\n","    (input_vertex, output_vertex, hidden_vertex, num_layer) = net_para\n","    net = FCN(input_vertex, output_vertex, hidden_vertex, num_layer)#.cuda()  #自己写的FCN代码\n","    net.load_state_dict(torch.load(net_file))\n","    return net\n","\n","def cal_evaluation(TP, TN, FP, FN):\n","    # 只需要输入混淆矩阵四个值，输出各种评价参数\n","    T = TP + TN + FP + FN\n","    acc = (TP + TN) / T\n","    pre = TP / (TP + FP + 1e-8)\n","    rcl = TP / (TP + FN + 1e-8)\n","    iou = TP / (TP + FN + FP + 1e-8)\n","    fone = 2 * pre * rcl / (pre + rcl + 1e-8)\n","    temp = ((TP + FP) * (TP + FN) + (TN + FP) * (TN + FN)) / (T * T)\n","    kpa = (acc - temp) / (1 - temp+1e-9)\n","    return acc, pre, rcl, iou, fone, kpa\n","def normalize(a):\n","    '''\n","    这是给7-16波段葵花数据以及17-18波段风数据进行一个拉伸，葵花亮温数据拉伸到0-1，经纬向风数据拉伸到[-1,1]\n","    1-18通道的五天所有数据的最小值：\n","    [ 4.49999981e-03  3.59999994e-03  2.19999999e-03  3.99999990e-04\n","      0.00000000e+00  0.00000000e+00  2.02559998e+02  1.88289993e+02\n","      1.84699997e+02  1.86860001e+02  1.85389999e+02  2.09250000e+02\n","      1.85529999e+02  1.83789993e+02  1.84559998e+02  1.86830002e+02\n","     -9.23541546e+00 -2.66013598e+00]\n","     1-18通道的五天所有数据的最大值：\n","    [  1.21569991   1.21569991   1.21569991   1.2184       1.21569991\n","       1.21569991 400.13000488 250.29998779 260.88000488 269.8500061\n","     313.47998047 287.67999268 316.47998047 313.77999878 305.1000061\n","     283.45999146   7.96795177   8.07158279]\n","\n","     20210430统一短长波的均值方差法\n","     mean=0.13332568109035492,std=0.10010378062725067\n","    mean=267.0377502441406,std=23.10291862487793\n","    mean=0.9318513870239258,std=3.01316237449646\n","    '''\n","    ary = np.copy(a)\n","    '''for i in range(ary.shape[1]):\n","        if 5 >= i >= 0:\n","            ary[:, i] = (ary[:, i] - 0) / (1.22 - 0)\n","        if 15 >= i >= 6:\n","            ary[:, i] = (ary[:, i] - 180) / (401 - 180)\n","        if 17 >= i >= 16:\n","            ary[:, i] = ary[:, i] / 10'''\n","\n","    '''\n","    for i in range(ary.shape[1]):\n","        if 5 >= i >= 0:\n","            ary[:,i] = (ary[:,i]-0.133)/0.1 +1.1\n","        if 15 >= i >= 6:\n","            ary[:,i] = (ary[:,i]-267.038)/23.103 +1.1\n","        if 17>= i >= 16:\n","            ary[:, i] = ary[:, i]-0.932 / 3.013 +1.1\n","    '''\n","    return ary\n","\n","def normalization(a):\n","    '''\n","    utc=00:00-00:50\n","    第1个波段的均值：0.17408108711242676，标准差：0.09180239588022232\n","    第2个波段的均值：0.15532344579696655，标准差：0.09411614388227463\n","    第3个波段的均值：0.13014985620975494，标准差：0.10350919514894485\n","    第4个波段的均值：0.17147856950759888，标准差：0.12056007981300354\n","    第5个波段的均值：0.10136411339044571，标准差：0.07353920489549637\n","    第6个波段的均值：0.06755834072828293，标准差：0.056784629821777344\n","    第7个波段的均值：291.5131530761719，标准差：12.34211540222168\n","    第8个波段的均值：235.845947265625，标准差：8.17346477508545\n","    第9个波段的均值：245.95281982421875，标准差：10.59644889831543\n","    第10个波段的均值：254.6614532470703，标准差：12.598808288574219\n","    第11个波段的均值：279.3176574707031，标准差：19.40409278869629\n","    第12个波段的均值：262.65631103515625，标准差：12.848060607910156\n","    第13个波段的均值：280.890380859375，标准差：20.239898681640625\n","    第14个波段的均值：279.4247741699219，标准差：20.82622718811035\n","    第15个波段的均值：276.036865234375，标准差：20.321340560913086\n","    第16个波段的均值：264.0698547363281，标准差：16.568769454956055\n","\n","    utc=01:00--???? 20210529\n","    第1个波段的均值：0.24988365173339844，标准差：0.1523149311542511\n","    第2个波段的均值：0.22707174718379974，标准差：0.1546255201101303\n","    第3个波段的均值：0.1965593546628952，标准差：0.16611580550670624\n","    第4个波段的均值：0.2700558304786682，标准差：0.19260701537132263\n","    第5个波段的均值：0.15735289454460144，标准差：0.10863379389047623\n","    第6个波段的均值：0.10653379559516907，标准差：0.083615243434906\n","    第7个波段的均值：294.7552795410156，标准差：12.182429313659668\n","    第8个波段的均值：235.458984375，标准差：7.029875755310059\n","    第9个波段的均值：245.67132568359375，标准差：9.387296676635742\n","    第10个波段的均值：254.40428161621094，标准差：11.410764694213867\n","    第11个波段的均值：279.58807373046875，标准差：18.392066955566406\n","    第12个波段的均值：262.9042663574219，标准差：12.510293960571289\n","    第13个波段的均值：281.0147705078125，标准差：19.294218063354492\n","    第14个波段的均值：279.3004150390625，标准差：19.88637924194336\n","    第15个波段的均值：275.607177734375，标准差：19.318004608154297\n","    第16个波段的均值：263.4919128417969，标准差：15.55377197265625\n","    第17个波段的均值：-0.40279674530029297，标准差：2.8014450073242188\n","    第18个波段的均值：2.749203681945801，标准差：1.7626181840896606\n","\n","    Process finished with exit code 0\n","\n","    '''\n","    Morning =[[0.17408109, 0.091802396], [0.15532345, 0.094116144], [0.13014986, 0.103509195], [0.17147857, 0.12056008],\n","              [0.10136411, 0.073539205], [0.06755834, 0.05678463], [291.51315, 12.342115], [235.84595, 8.173465],\n","              [245.95282, 10.596449], [254.66145, 12.598808], [279.31766, 19.404093], [262.6563, 12.848061],\n","              [280.89038, 20.239899], [279.42477, 20.826227], [276.03687, 20.32134], [264.06985, 16.56877],\n","              [-0.81586134, 2.9236693], [2.6795657, 1.8712212]]\n","    Noon = [[0.24988365, 0.15231493], [0.22707175, 0.15462552], [0.19655935, 0.1661158], [0.27005583, 0.19260702],\n","            [0.1573529, 0.108633794], [0.106533796, 0.08361524], [294.75528, 12.182429], [235.45898, 7.0298758],\n","            [245.67133, 9.387297], [254.40428, 11.410765], [279.58807, 18.392067], [262.90427, 12.510294],\n","            [281.01477, 19.294218], [279.3004, 19.88638], [275.60718, 19.318005], [263.4919, 15.553772],\n","            [-0.40279675, 2.801445], [2.7492037, 1.7626182]]\n","    ary = np.copy(a)\n","\n","    for i in range(ary.shape[1]-1):\n","        mean = Noon[i][0]\n","        std = Noon[i][1]\n","        ary[:, i] = (ary[:, i] - mean) / std\n","\n","\n","    return ary\n","\n","def choose_bands(data,bands):\n","    '''\n","    这是选择对应波段加入神经网络，\n","    bands是一个列表，里面的数字代表选取对应波段，使用的是人类语言，比如选择1，2，3波段输入网络就是bands=[1,2,3]\n","    '''\n","    output = data[:,bands[0]-1] #shape=750\n","    for band in bands[1:]:\n","        output = np.c_[output,data[:,band-1]]\n","    return output\n","import autogluon.core as ag\n","\n","def train(args,reporter):\n","    print('开始跑训练了！！！')\n","    print(mem.used)\n","    #bands指的是输入的通道序号，葵花卫星短到长波为从1到16，风数据从17到18，标签数据19（-1）\n","    input_vertex = len(bands)\n","    os.chdir(result_path)\n","      # 接口改在外面了\n","    mn = None\n","    mn1= None\n","    temp = 1000\n","    temp2=0\n","    # autogluon移花接木\n","    lr = args.lr\n","    \n","    echo = args.epochs\n","    #加载网络和优化器 (self, hidden_vertex,num_layer,input_vertex, output_vertex, BN,Drop)\n","    net = FCN(input_vertex)#.cuda()\n","    #net = load_network((input_vertex, output_vertex, hidden_vertex, num_layer), r'E:\\SmokeDetection\\source\\MLP_Results\\fcn_261.pth')\n","    opt = torch.optim.Adam(params=net.parameters(),lr=lr) #BatchSize=2000+\n","    #opt = torch.optim.SGD(params=net.parameters(),momentum=0.9,lr=lr)#weight_decay=L2正则\n","    #print(torch.cuda.is_available())\n","\n","    for e in range(echo):\n","        print(mem.used)\n","        loss_td = 0\n","        loss_vd = 0\n","\n","        tp, tn, fp, fn = 0, 0, 0, 0\n","        TP, TN, FP, FN = 0, 0, 0, 0\n","\n","        #random.shuffle(fns)\n","        #fns = [r'E:\\SmokeDetection\\source\\new_samples_64\\0823\\0000_1344_1088_smoke.tif'] ##!!!\n","        td_back_time = 0#每个周期的反向传播次数\n","        for step,(batchData, batchTarget) in enumerate(trainingDataLoader):\n","            opt.zero_grad()\n","            trainingPrediction = net(batchData)\n","            trainingLoss = torch.nn.CrossEntropyLoss()(trainingPrediction, batchTarget)\n","            #trainingLoss = torch.nn.MSELoss()(trainingPrediction, batchTarget.float())\n","            trainingLoss.backward()\n","            opt.step()\n","            trainingLoss.detach()\n","            trainingPrediction.detach()\n","            #print(trainingLoss)\n","            loss_td+=trainingLoss\n","            prediction = torch.max(trainingPrediction, 1)[1].cpu().numpy()\n","            gt = batchTarget.cpu().numpy()\n","            td_back_time +=1\n","            #print(step)\n","            for i in range(gt.shape[0]):\n","                if gt[i] == 1:\n","                    if prediction[i] == 1:\n","                        tp += 1\n","                    if prediction[i] == 0:\n","                        fn += 1\n","                        # find_pix_index(ary1[i,:], file)\n","                elif gt[i] == 0:\n","                    if prediction[i] == 0:\n","                        tn += 1\n","                    if prediction[i] == 1:\n","                        fp += 1\n","                        # find_pix_index(ary1[i,:], file)\n","            del prediction,trainingLoss\n","            loss_td=loss_td.detach()\n","        accuracy_td, precision_td, recall_td, iou_td, fone_td, kpa_td = cal_evaluation(tp, tn, fp, fn)\n","        loss_td /= td_back_time\n","        print('echo={},finish train time={}'.format(e+1, time.asctime()))\n","        os.chdir(result_path)\n","        reporter(epoch=e+1, accuracy=accuracy_td)\n","        print('Training precision：{}'.format(precision_td))\n","        print('Training recall：{}'.format(recall_td))\n","        with open('accuracy_td.txt', 'a') as f:\n","            f.write('{}\\n'.format(accuracy_td))\n","        with open('loss_td.txt', 'a') as f:\n","            f.write('{}\\n'.format(loss_td))\n","        with open('recall_td.txt', 'a') as f:\n","            f.write('{}\\n'.format(recall_td))\n","        with open('precision_td.txt', 'a') as f:\n","            f.write('{}\\n'.format(precision_td))\n","        with open('kappa_td.txt', 'a') as f:\n","            f.write('{}\\n'.format(kpa_td))\n","        with open('fone_td.txt', 'a') as f:\n","            f.write('{}\\n'.format(fone_td))\n","        with open('iou_td.txt', 'a') as f:\n","            f.write('{}\\n'.format(iou_td))\n","        del loss_td, trainingPrediction\n","        # ------------------------------------------验证数据---------------------------------------------#\n","        val_fns = vd_pth\n","        vd_back_time = 0\n","        net.eval()\n","        for step, (batchData, batchTarget) in enumerate(validationDataLoader):\n","            validationPrediction = net(batchData)\n","            validationLoss = torch.nn.CrossEntropyLoss()(validationPrediction, batchTarget)\n","            #validationLoss = torch.nn.MSELoss()(validationPrediction, batchTarget.float())\n","            validationLoss.detach()\n","            validationPrediction.detach()\n","            # print(trainingLoss)\n","            loss_vd += validationLoss\n","            #print('验证损失：{}'.format(validationLoss))\n","            prediction = torch.max(validationPrediction, 1)[1].cpu().numpy()\n","            gt = batchTarget.cpu().numpy()\n","            vd_back_time += 1\n","            # print(step)\n","            for i in range(gt.shape[0]):\n","                if gt[i] == 1:\n","                    if prediction[i] == 1:\n","                        TP += 1\n","                    if prediction[i] == 0:\n","                        FN += 1\n","                        # find_pix_index(ary1[i,:], file)\n","                elif gt[i] == 0:\n","                    if prediction[i] == 0:\n","                        TN += 1\n","                    if prediction[i] == 1:\n","                        FP += 1\n","                        # find_pix_index(ary1[i,:], file)\n","            loss_vd=loss_vd.detach()\n","            del prediction\n","        accuracy_vd, precision_vd, recall_vd, iou_vd, fone_vd, kpa_vd = cal_evaluation(TP, TN, FP, FN)\n","        print('echo={},finish validation time={}'.format(e+1, time.asctime()))\n","        net.train()\n","        os.chdir(result_path)\n","        loss_vd /= vd_back_time\n","        with open('accuracy_vd.txt', 'a') as f:\n","            f.write('{}\\n'.format(accuracy_vd))\n","        with open('loss_vd.txt', 'a') as f:\n","            f.write('{}\\n'.format(loss_vd))\n","        with open('recall_vd.txt', 'a') as f:\n","            f.write('{}\\n'.format(recall_vd))\n","        with open('precision_vd.txt', 'a') as f:\n","            f.write('{}\\n'.format(precision_vd))\n","        with open('fone_vd.txt', 'a') as f:\n","            f.write('{}\\n'.format(fone_vd))\n","        with open('iou_vd.txt', 'a') as f:\n","            f.write('{}\\n'.format(iou_vd))\n","        with open('kappa_vd.txt', 'a') as f:\n","            f.write('{}\\n'.format(kpa_vd))\n","        if mn is None:\n","            mn = 'fcn_{}loss.pth'.format(e)\n","            mn1 = 'fcn_{}f1.pth'.format(e)\n","            torch.save(net.state_dict(), mn)\n","            torch.save(net.state_dict(), mn1)\n","        if temp2 < fone_vd:  ##############################注意啊这里被改成看验证数据的f1了\n","            os.remove(mn1)\n","            mn1 = 'fcn_{}_f1.pth'.format(e)\n","            torch.save(net.state_dict(), mn1)\n","            temp2 = fone_vd\n","        if temp > loss_vd:  ##############################注意啊这里被改成看验证数据的loss了\n","            os.remove(mn)\n","            mn = 'fcn_{}_loss.pth'.format(e)\n","            torch.save(net.state_dict(), mn)\n","            temp = loss_vd\n","        print(time.asctime())\n","        del loss_vd,validationLoss,validationPrediction\n","        if e % 20 == 19:\n","            saveInterval = 'fcn_interval_{}.pth'.format(e)\n","            torch.save(net.state_dict(), saveInterval)\n","\n","#---------------------------------------------------------------主函数----------------------------------------------------\n","def load_smp_lst(td_pth,vd_pth,jdg=0):\n","    '''\n","    加载已有的训练数据和验证数据索引列表\n","    td_pth/vd_pth是训练和验证集的txt名字索引\n","    jdg为0的话就不会启动这个程序，算是一个保险吧。\n","    '''\n","    if jdg:\n","        with open(td_pth, 'r') as f:\n","            tra_data = f.readlines()\n","            print('成功加载已有训练集，包含样本{}个'.format(len(tra_data)))\n","        with open(vd_pth, 'r') as f:\n","            val_data = f.readlines()\n","            print('成功加载已有验证集，包含样本{}个'.format(len(val_data)))\n","        vd = []\n","        td = []\n","        for t in tra_data:\n","            td.append(t.strip('\\n'))\n","        for v in val_data:\n","            vd.append(v.strip('\\n'))\n","        return td,vd\n","@ ag.args(\n","lr = ag.space.Real(0.01, 0.2, log=True),\n","epochs = 100\n",")\n","def ar_train(args,reporter):\n","    return train(args,reporter)\n","\n","#不同数据集相同框架的MLP的存储路径，命名形式:每幅图采样像元数_采样方式\\随机次数\n","fn='/content/drive/MyDrive/smoke detecton/0_result'#结果存储\n","\n","\n","rootDataset = '/content/drive/MyDrive/smoke detecton/0'#数据所在地\n","\n","#定义一堆参数\n","print('开始加载'+fn.split('/')[-2]+'_'+fn.split('/')[-1])\n","num_layer = 3 #eval(fn.split('\\\\')[-1].split('_')[1])\n","hid_vertex = 256 #eval(fn.split('\\\\')[-1].split('_')[0])\n","td_pth = glob.glob(r'{}/*/*_td.npy'.format(rootDataset))#I:\\MLP_RESULT\\trainging_pixel_npy_0129\n","vd_pth =glob.glob(r'{}/*/*_vd.npy'.format(rootDataset))\n","#print(vd_pth)\n","filesize = 50000\n","bands =[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n","result_path = fn\n","batchsize = 1024\n","# 加载训练数据\n","fns = td_pth\n","tdShapeSize = filesize\n","trainingDataNumpy = np.zeros([tdShapeSize * len(fns), 19])\n","for file_num, file in enumerate(fns):\n","    trainingDataNumpy[(file_num) * tdShapeSize:(file_num + 1) * tdShapeSize, :] = np.load(file)\n","trainingTargetTorch = torch.from_numpy(trainingDataNumpy[:, -1])#.cuda()\n","# trainingDataNumpy = normalize(trainingDataNumpy)\n","trainingDataNumpy = normalization(trainingDataNumpy)\n","trainingDataNumpyNor = choose_bands(trainingDataNumpy, bands)\n","trainingDataTorch = torch.from_numpy(trainingDataNumpyNor)#.cuda()\n","trainingDataset = Data.TensorDataset(trainingDataTorch[:10000].float(), trainingTargetTorch[:10000].long())\n","print(trainingDataTorch.size(),trainingTargetTorch.size())\n","trainingDataLoader = Data.DataLoader(dataset=trainingDataset, batch_size=batchsize, shuffle=True)\n","\n","# 加载验证数据\n","vdShapesize = filesize // 2\n","validationDataNumpy = np.zeros([vdShapesize * len(fns), 19])\n","for file_num, file in enumerate(vd_pth):\n","    validationDataNumpy[(file_num) * vdShapesize:(file_num + 1) * vdShapesize, :] = np.load(file)\n","validationTargetTorch = torch.from_numpy(validationDataNumpy[:, -1])#.cuda()\n","# validationDataNumpy = normalize(validationDataNumpy)\n","validationDataNumpy = normalization(validationDataNumpy)\n","validationDataNumpyNor = choose_bands(validationDataNumpy, bands)\n","validationDataTorch = torch.from_numpy(validationDataNumpyNor)#.cuda()\n","# print(validationDataTorch.size(),validationTargetTorch.size())\n","validationDataset = Data.TensorDataset(validationDataTorch.float(), validationTargetTorch.long())\n","validationDataLoader = Data.DataLoader(dataset=validationDataset, batch_size=batchsize, shuffle=True)\n","print('数据组织完毕')\n","\n","\n","\n","#开始训练，根据文件夹上标注的层数和节点数训练\n","# myscheduler = ag.scheduler.FIFOScheduler(\n","#     ar_train,\n","#     resource={'num_cpus': 0, 'num_gpus': 0},\n","#     num_trials=2,\n","#     time_attr='epoch',\n","#     reward_attr='accuracy')\n","myscheduler = ag.scheduler.HyperbandScheduler(\n","    ar_train,\n","    resource={'num_cpus': 2, 'num_gpus': 1},\n","    num_trials=2,\n","    reward_attr='accuracy',\n","    time_attr='epoch',\n","    grace_period=1,\n","    reduction_factor=3,\n","    type='stopping')\n","\n","print(myscheduler)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gFxyTGdbNmSq","executionInfo":{"status":"ok","timestamp":1648813840302,"user_tz":-480,"elapsed":15251,"user":{"displayName":"莫宇皓","userId":"09578917465057778090"}},"outputId":"07f39605-acac-403f-d714-b0eaaa86abd5"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["开始加载smoke detecton_0_result\n","torch.Size([6600000, 16]) torch.Size([6600000])\n","数据组织完毕\n","HyperbandScheduler(terminator: HyperbandBracketManager(reward_attr: accuracy, time_attr: epoch, rung_levels: [1, 3, 9, 27, 81], max_t: 100, rung_systems: [Rung system: Iter 81.000: None | Iter 27.000: None | Iter 9.000: None | Iter 3.000: None | Iter 1.000: None])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/autogluon/core/space.py:482: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  cs.add_hyperparameter(hp)\n"]}]},{"cell_type":"code","source":["myscheduler.run() #崩溃了。。。\n","myscheduler.join_jobs()\n","myscheduler.get_training_curves(plot=True,use_legend=False)\n","print('The Best Configuration and Accuracy are: {}, {}'.format(myscheduler.get_best_config(),\n","                                                               myscheduler.get_best_reward()))\n","#(td_path, vd_path, result_path, bands, output_vertex,  echo, filesize)\n","#train函数的参数从左到右分别为：训练数据的路径及文件名；验证数据的路径及文件名；训练结果保存路径；训练数据选择的通道号码；\n","#网络输出层节点数；网络隐层各层节点数；网络隐层层数；训练过程的最大迭代次数；一次反传所包含的批量训练样本数；网络学习率；是否在激活函数后加BN层；是否在BN层后加Dropout，不加默认0\n","#train(td_path, vd_path, result_path, input_channels, output_vertex, hidden_vertex, num_layer, echo, batchsize, lr)[1,2,3,7,11,13,14,15,16]\n","print('跑完了')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d9f5617f48094b1daf1d7c0b3da6beaf","dfd59182ebbb4a7598db9d6cf235e5dc","0bd24cad6c80428eaed12446831a2278","1dd9927529014a128df419c042a27731","3cf55a4445934545a22cc97875774452","5738cecb9b464bcba945e81fa8f61356","84c8d434df82469095255b5ac41aacb3","820c5e2d9e0f44b48ddbd31175f555dd","b8268315a214491ba837ddc14fb05754","3df0cd26219a4c2e88856f6aa571d28b","7c571f3636b047d080cddcd0ff61ed70"]},"id":"m4ZLKamYShu1","outputId":"85e619cc-1eb5-48d7-9dce-78d4c860a791","executionInfo":{"status":"ok","timestamp":1648813916154,"user_tz":-480,"elapsed":16337,"user":{"displayName":"莫宇皓","userId":"09578917465057778090"}}},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9f5617f48094b1daf1d7c0b3da6beaf"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/autogluon/core/searcher/searcher.py:347: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  new_config = self.configspace.get_default_configuration().get_dictionary()\n"]},{"output_type":"stream","name":"stdout","text":["开始跑训练了！！！\n","11436544000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/autogluon/core/space.py:457: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  default_value=self._default)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/utils/custom_process.py\", line 16, in run\n","    mp.Process.run(self)\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/jobs.py\", line 60, in _worker\n","    ret = fn(**args)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/decorator.py\", line 60, in __call__\n","    output = self.f(args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/decorator.py\", line 143, in wrapper_call\n","    return func(*args, **kwargs)\n","  File \"<ipython-input-16-9bc93855b73e>\", line 344, in ar_train\n","    return train(args,reporter)\n","  File \"<ipython-input-16-9bc93855b73e>\", line 179, in train\n","    opt = torch.optim.Adam(params=net.parameters(),lr=lr) #BatchSize=2000+\n","AttributeError: 'FCN' object has no attribute 'parameters'\n","\n","Exception in thread Thread-27:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/reporter.py\", line 214, in run\n","    self.dist_reporter(done=True, traceback=traceback)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/reporter.py\", line 63, in __call__\n","    raise AutoGluonEarlyStop('Stopping!')\n","autogluon.core.utils.deprecate.AutoGluonEarlyStop: Stopping!\n","\n"]},{"output_type":"stream","name":"stdout","text":["开始跑训练了！！！\n","11436544000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/autogluon/core/space.py:457: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  default_value=self._default)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/utils/custom_process.py\", line 16, in run\n","    mp.Process.run(self)\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/jobs.py\", line 60, in _worker\n","    ret = fn(**args)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/decorator.py\", line 60, in __call__\n","    output = self.f(args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/decorator.py\", line 143, in wrapper_call\n","    return func(*args, **kwargs)\n","  File \"<ipython-input-16-9bc93855b73e>\", line 344, in ar_train\n","    return train(args,reporter)\n","  File \"<ipython-input-16-9bc93855b73e>\", line 179, in train\n","    opt = torch.optim.Adam(params=net.parameters(),lr=lr) #BatchSize=2000+\n","AttributeError: 'FCN' object has no attribute 'parameters'\n","\n","Exception in thread Thread-29:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/reporter.py\", line 214, in run\n","    self.dist_reporter(done=True, traceback=traceback)\n","  File \"/usr/local/lib/python3.7/dist-packages/autogluon/core/scheduler/reporter.py\", line 63, in __call__\n","    raise AutoGluonEarlyStop('Stopping!')\n","autogluon.core.utils.deprecate.AutoGluonEarlyStop: Stopping!\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":["The Best Configuration and Accuracy are: {'lr': 0.0447213595}, -inf\n","跑完了\n"]}]}]}